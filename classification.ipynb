{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f0dc03",
   "metadata": {},
   "source": [
    "# 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "970622fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sqlalchemy import create_engine\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b6363",
   "metadata": {},
   "source": [
    "# excel file to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d8569e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"./db_score_3_labels.xlsx\")\n",
    "\n",
    "conn = pymysql.connect(host='localhost', user='root', password=\",./l;'p[]a\", db='university')\n",
    "curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "db_connection_str = \"mysql+pymysql://root:,./l;'p[]a@localhost/university\"\n",
    "db_connection = create_engine(db_connection_str)\n",
    "data.to_sql(name='db_score', con=db_connection, if_exists='replace', index=False)\n",
    "\n",
    "curs.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b01b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy, precision, recall, f1_score 반환 함수\n",
    "def classification_performance_eval(y_test, y_predict):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    \n",
    "    for y, yp in zip(y_test, y_predict):\n",
    "        if y == 1 and yp == 1:\n",
    "            tp += 1\n",
    "        elif y == 1 and yp == -1:\n",
    "            fn += 1\n",
    "        elif y == -1 and yp == 1:\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "            \n",
    "    print(\"tp:\",tp, \"tn:\",tn, \"fp:\",fp, \"fn:\",fn)    \n",
    "\n",
    "    # zero division 예외 처리\n",
    "    accuracy = 0 if (tp+tn+fp+fn)==0 else (tp+tn)/(tp+tn+fp+fn)\n",
    "    precision = 0 if (tp+fp)==0 else(tp)/(tp+fp)\n",
    "    recall = 0 if (tp+fp)==0 else (tp)/(tp+fp)\n",
    "    f1_score = 0 if (precision+recall)==0 else 2*precision*recall / (precision+recall)\n",
    "        \n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43866d95",
   "metadata": {},
   "source": [
    "# 이진 분류 (grade B or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d706d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host='localhost', user='root', password=\",./l;'p[]a\", db='university')\n",
    "curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "sql = \"select * from db_score\"\n",
    "curs.execute(sql)\n",
    "\n",
    "data = curs.fetchall()\n",
    "\n",
    "curs.close()\n",
    "conn.close()\n",
    "\n",
    "X = [(t['homework'], t['discussion'], t['final']) for t in data]\n",
    "X = np.array(X)\n",
    "\n",
    "# grade가 B이면 1 아니면 -1 (이진 분류)\n",
    "y = [1 if (t['grade'] == 'B') else -1 for t in data]\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad45f13",
   "metadata": {},
   "source": [
    "# train_test_split SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c69da57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1  1\n",
      "  1 -1  1 -1 -1 -1 -1]\n",
      "tp: 5 tn: 19 fp: 3 fn: 4\n",
      "accuray: 0.7741935483870968\n",
      "precision: 0.625\n",
      "recall: 0.625\n",
      "f1_score: 0.625\n"
     ]
    }
   ],
   "source": [
    "# train_test_split SVM\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)\n",
    "svm = SVC(kernel='rbf', C=1e4).fit(X_train, y_train)\n",
    "y_predict = svm.predict(X_test)\n",
    "print(y_predict)\n",
    "    \n",
    "acc, prec, rec, f1 = classification_performance_eval(y_test, y_predict)\n",
    "\n",
    "print('accuray:', acc)\n",
    "print('precision:', prec)\n",
    "print('recall:', rec)\n",
    "print('f1_score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bad8ab",
   "metadata": {},
   "source": [
    "# train_test_split Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48404453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_predict: [ 1  1  1 -1  1 -1 -1  1  1  1 -1  1]\n",
      "tp: 4 tn: 3 fp: 4 fn: 1\n",
      "accuray: 0.5833333333333334\n",
      "precision: 0.5\n",
      "recall: 0.5\n",
      "f1_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# train_test_split Logistic Regression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.13, random_state=42)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(random_state=42, class_weight='balanced', C=1e2).fit(X_train, y_train)\n",
    "\n",
    "y_predict = lr.predict(X_test)\n",
    "print('y_predict:', y_predict)\n",
    "\n",
    "acc, prec, rec, f1 = classification_performance_eval(y_test, y_predict)\n",
    "print('accuray:', acc)\n",
    "print('precision:', prec)\n",
    "print('recall:', rec)\n",
    "print('f1_score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d7c0a",
   "metadata": {},
   "source": [
    "# K-fold SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "613b5543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 4 tn: 10 fp: 3 fn: 2\n",
      "tp: 4 tn: 8 fp: 4 fn: 3\n",
      "tp: 1 tn: 13 fp: 2 fn: 2\n",
      "tp: 2 tn: 8 fp: 0 fn: 8\n",
      "tp: 3 tn: 7 fp: 6 fn: 2\n",
      "accuray: 0.6514619883040935\n",
      "precision: 0.5476190476190476\n",
      "recall: 0.5476190476190476\n",
      "f1_score: 0.5476190476190476\n"
     ]
    }
   ],
   "source": [
    "# K-fold SVM\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score_ = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    svm = SVC(kernel='rbf', C=1e6).fit(X_train, y_train)\n",
    "    y_predict = svm.predict(X_test)\n",
    "\n",
    "\n",
    "    acc, prec, rec, f1 = classification_performance_eval(y_test, y_predict)\n",
    "    accuracy.append(acc)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    f1_score_.append(f1)\n",
    "        \n",
    "print('accuray:', statistics.mean(accuracy))\n",
    "print('precision:', statistics.mean(precision))\n",
    "print('recall:', statistics.mean(recall))\n",
    "print('f1_score:', statistics.mean(f1_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf000c9e",
   "metadata": {},
   "source": [
    "# K-fold Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d79169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 4 tn: 8 fp: 9 fn: 2\n",
      "tp: 6 tn: 6 fp: 9 fn: 2\n",
      "tp: 2 tn: 7 fp: 7 fn: 7\n",
      "tp: 5 tn: 5 fp: 10 fn: 3\n",
      "accuray: 0.46739130434782605\n",
      "precision: 0.3158119658119658\n",
      "recall: 0.3158119658119658\n",
      "f1_score: 0.3158119658119658\n"
     ]
    }
   ],
   "source": [
    "# K-fold Logistic Regression\n",
    "\n",
    "kf = KFold(n_splits=4, random_state=42, shuffle=True)\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score_ = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "    lr = LogisticRegression(random_state=42, class_weight='balanced', C=1).fit(X_train, y_train)\n",
    "    y_predict= lr.predict(X_test)\n",
    "\n",
    "    acc, prec, rec, f1 = classification_performance_eval(y_test, y_predict)\n",
    "    accuracy.append(acc)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    f1_score_.append(f1)\n",
    "    \n",
    "print('accuray:', statistics.mean(accuracy))\n",
    "print('precision:', statistics.mean(precision))\n",
    "print('recall:', statistics.mean(recall))\n",
    "print('f1_score:', statistics.mean(f1_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2491a131",
   "metadata": {},
   "source": [
    "# 다중 클래스 분류(grade A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9782af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host='localhost', user='root', password=\",./l;'p[]a\", db='university')\n",
    "curs = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "sql = \"select * from db_score\"\n",
    "curs.execute(sql)\n",
    "\n",
    "data = curs.fetchall()\n",
    "\n",
    "curs.close()\n",
    "conn.close()\n",
    "\n",
    "X = [(t['homework'], t['discussion'], t['final']) for t in data]\n",
    "X = np.array(X)\n",
    "\n",
    "y = [0 if (t['grade'] == 'A') else 1 if (t['grade'] == 'B') else 2 for t in data]\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d597dba",
   "metadata": {},
   "source": [
    "# train_test_split SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6c2f302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 2 0 0 1 1 0 2 2 1 2 1 0 0 0 0 1 2 0 1 1 1 1 0 1 2 1 2 0]\n",
      "accuray: 0.7419354838709677\n",
      "precision: [0.90909091 0.53846154 0.85714286]\n",
      "recall: [0.90909091 0.77777778 0.54545455]\n",
      "f1_score: [0.90909091 0.63636364 0.66666667]\n"
     ]
    }
   ],
   "source": [
    "# train_test_split SVM\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)\n",
    "\n",
    "svm = SVC(kernel='rbf', C=5).fit(X_train, y_train)\n",
    "y_predict = svm.predict(X_test)\n",
    "print(y_predict)\n",
    "    \n",
    "print('accuray:', accuracy_score(y_test, y_predict))\n",
    "print('precision:', precision_score(y_test, y_predict, average=None))\n",
    "print('recall:', recall_score(y_test, y_predict, average=None))\n",
    "print('f1_score:', f1_score(y_test, y_predict, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5dd9b",
   "metadata": {},
   "source": [
    "# train_test_split Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e85cda9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_predict: [1 1 1 2 0 0 0 2 0 2 2 1 2 1 0 0 0 1 1 2 0 1 2 1 0 0 1 2 1 2 0]\n",
      "accuray: 0.7419354838709677\n",
      "precision: [0.81818182 0.54545455 0.88888889]\n",
      "recall: [0.81818182 0.66666667 0.72727273]\n",
      "f1_score: [0.81818182 0.6        0.8       ]\n"
     ]
    }
   ],
   "source": [
    "# train_test_split Logistic Regression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(random_state=42, class_weight='balanced', C=1e10).fit(X_train, y_train)\n",
    "\n",
    "y_predict = lr.predict(X_test)\n",
    "print('y_predict:', y_predict)\n",
    "\n",
    "print('accuray:', accuracy_score(y_test, y_predict))\n",
    "print('precision:', precision_score(y_test, y_predict, average=None))\n",
    "print('recall:', recall_score(y_test, y_predict, average=None))\n",
    "print('f1_score:', f1_score(y_test, y_predict, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b1a50",
   "metadata": {},
   "source": [
    "# k-fold SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98bbcbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuray: 0.543859649122807\n",
      "precision: 0.5433333333333333 0.3904761904761905 0.6709956709956709\n",
      "recall: 0.5457142857142857 0.3057142857142857 0.689047619047619\n",
      "f1_score: 0.5167099567099568 0.32945054945054947 0.648180591338486\n"
     ]
    }
   ],
   "source": [
    "# k-fold SVM\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "accuracy = []\n",
    "precision_A, precision_B, precision_C = [], [], []\n",
    "recall_A, recall_B, recall_C = [], [], []\n",
    "f1_score_A, f1_score_B, f1_score_C = [], [], []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    svm = SVC(kernel='rbf', C=1e10).fit(X_train, y_train)\n",
    "    y_predict = svm.predict(X_test)\n",
    "\n",
    "    prec = precision_score(y_test, y_predict, average=None, zero_division=0)\n",
    "    rec = recall_score(y_test, y_predict, average=None, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_predict, average=None, zero_division=0)\n",
    "    \n",
    "    accuracy.append(accuracy_score(y_test, y_predict))\n",
    "    precision_A.append(prec[0])\n",
    "    precision_B.append(prec[1])\n",
    "    precision_C.append(prec[2])\n",
    "    recall_A.append(rec[0])\n",
    "    recall_B.append(rec[1])\n",
    "    recall_C.append(rec[2])\n",
    "    f1_score_A.append(f1[0])\n",
    "    f1_score_B.append(f1[1])\n",
    "    f1_score_C.append(f1[2])\n",
    "    \n",
    "print('accuray:', statistics.mean(accuracy))\n",
    "print('precision:', statistics.mean(precision_A), statistics.mean(precision_B), statistics.mean(precision_C) )\n",
    "print('recall:', statistics.mean(recall_A), statistics.mean(recall_B), statistics.mean(recall_C))\n",
    "print('f1_score:', statistics.mean(f1_score_A), statistics.mean(f1_score_B), statistics.mean(f1_score_C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e754522",
   "metadata": {},
   "source": [
    "# k-fold Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3215767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuray: 0.6502923976608187\n",
      "precision: 0.6742857142857143 0.6133333333333333 0.7452380952380953\n",
      "recall: 0.5842857142857143 0.4676190476190476 0.8678571428571429\n",
      "f1_score: 0.61 0.47883449883449886 0.7919413919413919\n"
     ]
    }
   ],
   "source": [
    "# k-fold Logistic Regression\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "accuracy = []\n",
    "precision_A, precision_B, precision_C = [], [], []\n",
    "recall_A, recall_B, recall_C = [], [], []\n",
    "f1_score_A, f1_score_B, f1_score_C = [], [], []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "    lr = LogisticRegression(random_state=42, class_weight='balanced', C=1).fit(X_train, y_train)\n",
    "    y_predict= lr.predict(X_test)\n",
    "\n",
    "    prec = precision_score(y_test, y_predict, average=None, zero_division=0)\n",
    "    rec = recall_score(y_test, y_predict, average=None, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_predict, average=None, zero_division=0)\n",
    "    \n",
    "    accuracy.append(accuracy_score(y_test, y_predict))\n",
    "    precision_A.append(prec[0])\n",
    "    precision_B.append(prec[1])\n",
    "    precision_C.append(prec[2])\n",
    "    recall_A.append(rec[0])\n",
    "    recall_B.append(rec[1])\n",
    "    recall_C.append(rec[2])\n",
    "    f1_score_A.append(f1[0])\n",
    "    f1_score_B.append(f1[1])\n",
    "    f1_score_C.append(f1[2])\n",
    "    \n",
    "print('accuray:', statistics.mean(accuracy))\n",
    "print('precision:', statistics.mean(precision_A), statistics.mean(precision_B), statistics.mean(precision_C) )\n",
    "print('recall:', statistics.mean(recall_A), statistics.mean(recall_B), statistics.mean(recall_C))\n",
    "print('f1_score:', statistics.mean(f1_score_A), statistics.mean(f1_score_B), statistics.mean(f1_score_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee99e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
